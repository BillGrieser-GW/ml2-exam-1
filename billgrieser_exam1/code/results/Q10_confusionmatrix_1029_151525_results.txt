Net(
  (layer_01): Linear(in_features=3072, out_features=1500, bias=True)
  (dropout_layer): Dropout(p=0.5)
  (output_layer): Linear(in_features=1500, out_features=10, bias=True)
)

Hidden Layer sizes: [(1500,)]
Total network weights + biases: 4624510
Epochs: 0
Learning rate: 0.005
Optimizer: Adagrad (
Parameter Group 0
    initial_accumulator_value: 0
    lr: 0.005
    lr_decay: 0
    weight_decay: 0
)
Transfer Function: <class 'torch.nn.modules.activation.ReLU'>
Batch Size: 32
